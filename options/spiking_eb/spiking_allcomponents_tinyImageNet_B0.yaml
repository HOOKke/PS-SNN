dataset: tinyimagenet
data_path: ./store/dataset/tiny-imagenet-200

order:
  - [33, 146, 79, 19, 23, 131, 12, 187, 174, 32, 86, 123, 109, 171, 42, 170, 179, 31, 36, 10, 180, 9, 121, 27, 57, 157, 96, 163, 160, 41, 43, 18, 169, 154, 119, 159, 15, 17, 63, 28, 76, 183, 4, 168, 80, 104, 161, 156, 37, 35, 11, 40, 14, 192, 134, 38, 94, 102, 113, 105, 111, 67, 87, 83, 91, 188, 89, 116, 52, 101, 167, 198, 139, 46, 61, 164, 54, 175, 71, 191, 196, 92, 49, 181, 140, 144, 125, 199, 177, 45, 73, 130, 186, 51, 136, 70, 69, 149, 98, 1, 29, 64, 132, 21, 82, 118, 153, 147, 78, 143, 90, 39, 152, 60, 3, 137, 133, 148, 50, 107, 66, 20, 184, 13, 197, 84, 182, 22, 95, 93, 44, 176, 103, 62, 122, 8, 100, 150, 127, 72, 77, 48, 129, 165, 128, 85, 194, 75, 47, 25, 142, 106, 172, 74, 117, 162, 158, 88, 59, 141, 193, 112, 56, 135, 173, 108, 55, 189, 2, 138, 190, 6, 5, 185, 81, 26, 151, 58, 68, 114, 178, 0, 155, 110, 99, 7, 124, 24, 53, 97, 166, 120, 115, 126, 30, 65, 16, 195, 145, 34]
seed: [1]

# -> this experiment setting has not been best finetuned
initial_increment: 0
increment: 20
label: alade_snn_tinyimagenet_b0_10steps

model: spiking_mutable
convnet: spiking_resnet18_modified
train_head: "softmax"  # -> however this parameter doesn't have any use for now
infer_head: "softmax"
use_bias: False
last_relu: False

scheduler: 'multistep'
epochs: 170
batch_size: 64
weight_decay: 0.0005  # -> may be an important part (and initial)
lr: 0.1
optimizer: sgd

dynamic_weight_decay: False
scheduling:
  - 100
  - 120
lr_decay: 0.1
keep_memory: True
val_per_n_epoch: -1
random_classes: False
warmup: True
warmup_epochs: 10

# some options for the new method
der: True
aux_n+1: True
distillation: "none"
# -> I NEED TO USE TET LOSS REMEMBER
spiking: True
T: 4
TET_config:
  enable: True  # -> important part
  TET_mean: 1.0
#  TET_lamb: 0.001
  TET_lamb: 0.

reuse_oldfc: False
weight_normalization: False

conv_config:
  spiking_neuron: zif-lif
  surrogate_function: none

temperature: 2.0
use_aux: True
supp_o2n: True  # -> important part
step_kl: False  # -> important part
recover_old: False
kl_config: all_sample  # -> important part
#kl_config: old_sample  # -> important part
aug_config:
  aug_st_ep: 130
  main_enable: False  # -> important part
  main_range: all_sample
  main_part: latter_logit
  main_minus: False
  aux_enable: False  # -> important part
  aux_range: all_sample
  aux_part: latter_logit
  aux_minus: False
  aux_kl: none

# the memory options
coreset_strategy: "iCaRL"
mem_size_mode: uniform_fixed_total_mem
memory_size: 2000
fixed_memory_per_cls: 10

initial_training_config:
  lr: 0.1
  optimizer: sgd
  weight_decay: 0.0005  # -> may be an important part
  scheduling:
    - 100
    - 120
  lr_decay: 0.1
  epochs: 170

decouple:
  enable: True
  epochs: 30
  lr: 0.1
  scheduling:
    - 15
  lr_decay: 0.1
  weight_decay: 0.0005
  temperature: 1.0  # 1.0 5.0
  #  fullset: True
  reuse_old: False
  o2n_fix: False
  refresh_param: True
  loader_type: balanced
  block_fix: none
  logit_ctrl: True  # -> important part

# MeanLess part
postprocessor:
  enable: False
  type: 'bic' #'bic', 'wa'
  epochs: 1
  batch_size: 128
  lr: 0.1
  scheduling:
    - 40
    - 60
  lr_decay_factor: 0.1
  weight_decay: 0.0005
#####################
